{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\development\\llm\\workshop\\env\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.4.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "#   {\n",
    "#     'role': 'user',\n",
    "#     'content': 'Why is the sky blue?',\n",
    "#   },\n",
    "# ])\n",
    "# print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "# print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Name:** SmartWatch Fusion X\n",
      "\n",
      "The SmartWatch Fusion X is an innovative wearable device designed to transform your daily routine into a seamless experience. With its sleek and modern design, this smartwatch seamlessly blends style with functionality, ensuring that you stay connected, on top of your game, and in sync with the world around you.\n",
      "\n",
      "**Features:**\n",
      "\n",
      "• Water-resistant up to 50 meters for an immersive aquatic experience\n",
      "• Long-lasting battery life of up to 7 days, allowing for uninterrupted wear\n",
      "• Advanced health monitoring features, including heart rate tracking, sleep quality analysis, and stress level detection\n",
      "• Wireless charging capabilities for a hassle-free recharging process\n",
      "• Compatible with both iOS and Android devices for seamless connectivity\n",
      "\n",
      "**Dimensions:**\n",
      "\n",
      "- Length: 47mm\n",
      "- Width: 33.5mm\n",
      "- Height: 11.4mm"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are a helpful copy writer for an e commerce company that uploads products to the site. \n",
    "Given an one line description of a product write a complete content about the product that can be used as an mock data.\n",
    "The generated content must include three sections:\n",
    "    Product Description (Paragraph)\n",
    "    Features: Salient Features of the product (List)\n",
    "    Dimensions: List down the dimensions of the product if applicable (user provided or made up values)\n",
    "\n",
    "Just create the content dont add any sentence at the beginning  \n",
    "\"\"\"\n",
    "\n",
    "stream: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': prompt,\n",
    "  },\n",
    "],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
      "2. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths.\n",
      "3. This is because the smaller molecules are more effective at scattering the shorter wavelengths due to their size and density.\n",
      "4. As a result, the blue light is dispersed in all directions, reaching our eyes from all parts of the sky.\n",
      "5. Our brains interpret this scattered blue light as the color of the sky.\n",
      "\n",
      "The reason why we don't see the sky as a uniform blue is because of the Earth's atmosphere. The atmosphere scatters light in different ways, depending on its composition and temperature. For example:\n",
      "\n",
      "* At sunrise and sunset, the sky can take on hues of red, orange, and pink due to the scattering of longer wavelengths by atmospheric particles.\n",
      "* During nighttime, the sky appears dark because there is less sunlight to scatter.\n",
      "\n",
      "So, in summary, the sky appears blue because of Rayleigh scattering, which scatters shorter (blue) wavelengths of light more than longer (red) wavelengths."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate this, I'll follow the order of operations (PEMDAS):\n",
      "\n",
      "1. Multiply 77 and 77:\n",
      "77 * 77 = 5929\n",
      "2. Divide the result by 88:\n",
      "5929 ÷ 88 ≈ 67.25\n",
      "\n",
      "So, 77*77/88 ≈ 67.25"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'What is 77*77/88? Do the calculation step by step and try to be precise'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic\n",
    "\n",
    "- Introduce llm from there\n",
    "- Introduce prompt templates\n",
    "- Introduce strucutured response raw\n",
    "- Structured response json mode\n",
    "- Structured response Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, values: dict) -> dict:\n",
    "        setup = values.get(\"setup\")\n",
    "        if setup and setup[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return values\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
